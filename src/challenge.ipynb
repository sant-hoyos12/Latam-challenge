{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latam Data Engineer Challenge\n",
    "*Santiago Hoyos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo todas las librerías a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un DataFrame de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo JSON en un DataFrame de Pandas\n",
    "df = pd.read_json(file_path, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deseo entender la estructura del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información del DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117407 entries, 0 to 117406\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count   Dtype              \n",
      "---  ------           --------------   -----              \n",
      " 0   url              117407 non-null  object             \n",
      " 1   date             117407 non-null  datetime64[ns, UTC]\n",
      " 2   content          117407 non-null  object             \n",
      " 3   renderedContent  117407 non-null  object             \n",
      " 4   id               117407 non-null  int64              \n",
      " 5   user             117407 non-null  object             \n",
      " 6   outlinks         117407 non-null  object             \n",
      " 7   tcooutlinks      117407 non-null  object             \n",
      " 8   replyCount       117407 non-null  int64              \n",
      " 9   retweetCount     117407 non-null  int64              \n",
      " 10  likeCount        117407 non-null  int64              \n",
      " 11  quoteCount       117407 non-null  int64              \n",
      " 12  conversationId   117407 non-null  int64              \n",
      " 13  lang             117407 non-null  object             \n",
      " 14  source           117407 non-null  object             \n",
      " 15  sourceUrl        116495 non-null  object             \n",
      " 16  sourceLabel      116495 non-null  object             \n",
      " 17  media            28109 non-null   object             \n",
      " 18  retweetedTweet   0 non-null       float64            \n",
      " 19  quotedTweet      41436 non-null   object             \n",
      " 20  mentionedUsers   38034 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(6), object(13)\n",
      "memory usage: 18.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del DataFrame para visualizar la estructura y los datos\n",
    "#print(\"Primeras filas del DataFrame:\")\n",
    "#print(df.head(5))\n",
    "\n",
    "# Ver la información general del DataFrame\n",
    "print(\"\\nInformación del DataFrame:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'username': 'narendramodi', 'displayname': '...\n",
       "1    [{'username': 'Kisanektamorcha', 'displayname'...\n",
       "2                                                 None\n",
       "3    [{'username': 'ReallySwara', 'displayname': 'S...\n",
       "4                                                 None\n",
       "Name: mentionedUsers, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(df['user'])\n",
    "#df['mentionedUsers'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días. Debe incluir las siguientes funciones:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización tiempo de ejecución**\n",
    "\n",
    "Explicación de q1_time:\n",
    "\n",
    "1. Carga de Datos Eficiente: En este enfoque, se utiliza la biblioteca pandas para cargar el archivo JSON en un DataFrame. pandas está altamente optimizado para el procesamiento de datos tabulares y es muy eficiente para manejar grandes conjuntos de datos.\n",
    "\n",
    "2. Operaciones Vectorizadas y Uso de Funciones Lambda: Se aprovechan las operaciones vectorizadas de pandas para realizar manipulaciones de datos en grandes conjuntos de datos de manera eficiente. Por ejemplo, la conversión de la columna de fecha a datetime y luego a datetime.date se realiza de manera vectorizada utilizando el método pd.to_datetime y dt.date. Además, las funciones lambda son utilizadas para aplicar transformaciones simples a los datos de manera eficiente.\n",
    "\n",
    "3. Agrupación y Reducción de Datos: Se utiliza la función groupby de pandas para agrupar los datos por fecha y contar el número de tweets en cada fecha. Esto se realiza de manera muy eficiente en términos de tiempo de ejecución.\n",
    "\n",
    "4. Selección de los Top Usuarios: Para cada una de las 10 fechas con más tweets, se selecciona el usuario que más publicó en esa fecha. Esto se hace de manera eficiente utilizando operaciones de agrupación y clasificación de pandas.\n",
    "\n",
    "Por qué es Bueno para Optimizar el Tiempo de Ejecución:\n",
    "\n",
    "- pandas es altamente eficiente para el procesamiento de datos tabulares y proporciona operaciones optimizadas que pueden manejar grandes volúmenes de datos de manera eficiente.\n",
    "\n",
    "- Las operaciones vectorizadas y el uso de funciones **lambda** permiten realizar transformaciones y cálculos en los datos de manera eficiente, evitando bucles explícitos.\n",
    "\n",
    "- La agrupación de datos realizada por pandas permite procesar grandes conjuntos de datos de manera rápida y eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import datetime\n",
    "#file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "\n",
    "#@profile   #se puede descomentar para correr la función en la terminal con python -m memory_profiler q1_time.py y ver el uso de memoria.\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Cargar el archivo JSON en un DataFrame de Pandas\n",
    "    #df = pd.read_json(file_path, lines=True)\n",
    "    \n",
    "    # Extraer el 'username' de la columna 'user'\n",
    "    df['username'] = df['user'].apply(lambda user: user['username'])\n",
    "    \n",
    "    # Convertir la columna 'date' a datetime.date\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "    \n",
    "    # Agrupar por fecha y contar los tweets\n",
    "    tweet_counts = df.groupby(df['date'])['id'].count().reset_index()\n",
    "    \n",
    "    # Ordenar por el conteo de tweets descendente y obtener las 10 fechas principales\n",
    "    top_dates = tweet_counts.sort_values('id', ascending=False).head(10)['date'].tolist()\n",
    "    \n",
    "    # Encontrar el usuario con más tweets para cada fecha principal\n",
    "    top_users = []\n",
    "    for date in top_dates:\n",
    "        date_df = df[df['date'] == date]\n",
    "        top_user = date_df.groupby('username')['id'].count().sort_values(ascending=False).index[0]\n",
    "        top_users.append((date, top_user))\n",
    "    \n",
    "    return top_users\n",
    "\n",
    "print(q1_time(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         136942 function calls (136536 primitive calls) in 0.689 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   117407    0.028    0.000    0.028    0.000 1612929132.py:14(<lambda>)\n",
      "        1    0.032    0.032    0.687    0.687 1612929132.py:9(q1_time)\n",
      "       23    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1033(_handle_fromlist)\n",
      "        1    0.002    0.002    0.689    0.689 <string>:1(<module>)\n",
      "       24    0.000    0.000    0.000    0.000 _decorators.py:218(_format_argument_list)\n",
      "    24/23    0.000    0.000    0.007    0.000 _decorators.py:308(wrapper)\n",
      "       40    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\n",
      "       40    0.000    0.000    0.000    0.000 _dtype.py:330(_name_includes_bit_suffix)\n",
      "       40    0.000    0.000    0.000    0.000 _dtype.py:346(_name_get)\n",
      "        1    0.000    0.000    0.000    0.000 _methods.py:39(_amax)\n",
      "        1    0.000    0.000    0.000    0.000 _methods.py:43(_amin)\n",
      "       43    0.000    0.000    0.001    0.000 _methods.py:55(_any)\n",
      "        1    0.000    0.000    0.001    0.001 _mixins.py:154(take)\n",
      "       22    0.000    0.000    0.000    0.000 _ufunc_config.py:132(geterr)\n",
      "       22    0.000    0.000    0.000    0.000 _ufunc_config.py:33(seterr)\n",
      "       11    0.000    0.000    0.000    0.000 _ufunc_config.py:426(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 _ufunc_config.py:430(__enter__)\n",
      "       11    0.000    0.000    0.000    0.000 _ufunc_config.py:435(__exit__)\n",
      "       25    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\n",
      "       11    0.000    0.000    0.000    0.000 _validators.py:452(validate_ascending)\n",
      "       11    0.000    0.000    0.000    0.000 abc.py:100(__subclasscheck__)\n",
      "        6    0.000    0.000    0.000    0.000 abc.py:96(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 accessor.py:179(__get__)\n",
      "        1    0.000    0.000    0.023    0.023 accessor.py:80(_getter)\n",
      "        1    0.000    0.000    0.000    0.000 accessors.py:483(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 accessors.py:54(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 accessors.py:65(_get_values)\n",
      "        1    0.000    0.000    0.023    0.023 accessors.py:83(_delegate_property_get)\n",
      "       12    0.000    0.000    0.000    0.000 algorithms.py:115(_ensure_data)\n",
      "       12    0.000    0.000    0.001    0.000 algorithms.py:1477(take)\n",
      "       11    0.000    0.000    0.021    0.002 algorithms.py:1788(safe_sort)\n",
      "       23    0.000    0.000    0.000    0.000 algorithms.py:195(_reconstruct_data)\n",
      "       12    0.000    0.000    0.000    0.000 algorithms.py:233(_ensure_arraylike)\n",
      "       12    0.000    0.000    0.009    0.001 algorithms.py:267(_get_hashtable_algo)\n",
      "       12    0.000    0.000    0.009    0.001 algorithms.py:285(_check_object_for_strings)\n",
      "        1    0.000    0.000    0.006    0.006 algorithms.py:313(unique)\n",
      "        1    0.000    0.000    0.006    0.006 algorithms.py:410(unique_with_mask)\n",
      "       11    0.001    0.000    0.050    0.005 algorithms.py:522(factorize_array)\n",
      "       11    0.001    0.000    0.073    0.007 algorithms.py:596(factorize)\n",
      "       11    0.000    0.000    0.000    0.000 algorithms.py:846(resolve_na_sentinel)\n",
      "       11    0.000    0.000    0.000    0.000 algorithms.py:898(_re_wrap_factorize)\n",
      "       12    0.000    0.000    0.000    0.000 api.py:381(default_index)\n",
      "        1    0.000    0.000    0.000    0.000 apply.py:1066(__init__)\n",
      "        1    0.004    0.004    0.070    0.070 apply.py:1085(apply)\n",
      "        1    0.000    0.000    0.000    0.000 apply.py:109(__init__)\n",
      "        1    0.000    0.000    0.066    0.066 apply.py:1136(apply_standard)\n",
      "       10    0.000    0.000    0.063    0.006 array_ops.py:231(comparison_op)\n",
      "       10    0.000    0.000    0.063    0.006 array_ops.py:60(comp_method_OBJECT_ARRAY)\n",
      "       10    0.000    0.000    0.066    0.007 arraylike.py:41(__eq__)\n",
      "        1    0.000    0.000    0.005    0.005 astype.py:192(astype_array)\n",
      "        1    0.000    0.000    0.005    0.005 astype.py:239(astype_array_safe)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:1025(view)\n",
      "       11    0.000    0.000    0.001    0.000 base.py:1170(take)\n",
      "       11    0.000    0.000    0.000    0.000 base.py:1196(_maybe_disallow_fill)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:161(_freeze)\n",
      "       11    0.000    0.000    0.000    0.000 base.py:163(array)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:168(__setattr__)\n",
      "       26    0.000    0.000    0.000    0.000 base.py:1736(name)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1787(_get_default_index_names)\n",
      "       11    0.000    0.000    0.000    0.000 base.py:1822(_get_names)\n",
      "       11    0.000    0.000    0.000    0.000 base.py:1825(_set_names)\n",
      "       11    0.000    0.000    0.000    0.000 base.py:1854(set_names)\n",
      "       11    0.000    0.000    0.001    0.000 base.py:192(grouped_reduce)\n",
      "       11    0.000    0.000    0.000    0.000 base.py:1965(rename)\n",
      "       11    0.000    0.000    0.000    0.000 base.py:216(_obj_with_exclusions)\n",
      "       11    0.000    0.000    0.001    0.000 base.py:231(__getitem__)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:2383(is_unique)\n",
      "        2    0.000    0.000    0.001    0.001 base.py:2423(is_boolean)\n",
      "       16    0.000    0.000    0.000    0.000 base.py:243(disallow_kwargs)\n",
      "        2    0.000    0.000    0.001    0.001 base.py:2747(inferred_type)\n",
      "       23    0.000    0.000    0.000    0.000 base.py:2754(_is_all_dates)\n",
      "       25    0.000    0.000    0.000    0.000 base.py:2785(_is_multi)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:2803(_na_value)\n",
      "       25    0.000    0.000    0.000    0.000 base.py:286(is_dtype)\n",
      "      108    0.000    0.000    0.000    0.000 base.py:324(ndim)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:356(size)\n",
      "       29    0.000    0.000    0.000    0.000 base.py:3756(get_loc)\n",
      "        1    0.000    0.000    0.007    0.007 base.py:3886(get_indexer)\n",
      "        1    0.000    0.000    0.005    0.005 base.py:3973(_get_indexer)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4018(_check_indexing_method)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:415(_engine_type)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4203(_validate_positional_slice)\n",
      "    18/16    0.000    0.000    0.003    0.000 base.py:432(__new__)\n",
      "       14    0.000    0.000    0.000    0.000 base.py:46(__len__)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:494(find)\n",
      "      108    0.000    0.000    0.000    0.000 base.py:5128(_values)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:5154(_get_engine_target)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5242(_validate_fill_value)\n",
      "       65    0.000    0.000    0.000    0.000 base.py:5292(__contains__)\n",
      "       74    0.002    0.000    0.003    0.000 base.py:5342(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5394(_getitem_slice)\n",
      "       15    0.000    0.000    0.000    0.000 base.py:54(shape)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:543(empty)\n",
      "       21    0.000    0.000    0.000    0.000 base.py:5502(equals)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:557(<genexpr>)\n",
      "       45    0.000    0.000    0.000    0.000 base.py:56(<genexpr>)\n",
      "       16    0.000    0.000    0.000    0.000 base.py:576(_ensure_array)\n",
      "       41    0.000    0.000    0.000    0.000 base.py:58(_validate_set_axis)\n",
      "       16    0.000    0.000    0.000    0.000 base.py:590(_dtype_to_subclass)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:6231(_index_as_unique)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:6243(_maybe_promote)\n",
      "        1    0.000    0.000    0.001    0.001 base.py:6323(_should_compare)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:6341(_is_comparable_dtype)\n",
      "       29    0.000    0.000    0.000    0.000 base.py:6607(_maybe_cast_indexer)\n",
      "        1    0.000    0.000    0.001    0.001 base.py:6614(_maybe_cast_listlike_indexer)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:6620(_validate_indexer)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:6882(insert)\n",
      "       53    0.000    0.000    0.000    0.000 base.py:692(_simple_new)\n",
      "       15    0.000    0.000    0.004    0.000 base.py:710(_with_infer)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:721(tolist)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:730(_constructor)\n",
      "       67    0.000    0.000    0.002    0.000 base.py:7315(ensure_index)\n",
      "       49    0.000    0.000    0.000    0.000 base.py:7410(maybe_extract_name)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:742(__iter__)\n",
      "       16    0.000    0.000    0.001    0.000 base.py:7434(_maybe_cast_data_without_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:7494(unpack_nested_dtype)\n",
      "        1    0.000    0.000    0.008    0.008 base.py:796(_map_values)\n",
      "       13    0.000    0.000    0.000    0.000 base.py:823(_view)\n",
      "       21    0.000    0.000    0.000    0.000 base.py:841(is_)\n",
      "       65    0.000    0.000    0.000    0.000 base.py:872(_reset_identity)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:883(_engine)\n",
      "       96    0.000    0.000    0.000    0.000 base.py:927(__len__)\n",
      "       36    0.000    0.000    0.000    0.000 base.py:988(dtype)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:161(_consolidate_key)\n",
      "        2    0.000    0.000    0.087    0.043 blocks.py:1917(delete)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:201(fill_value)\n",
      "       42    0.000    0.000    0.000    0.000 blocks.py:2088(maybe_coerce_values)\n",
      "       41    0.000    0.000    0.000    0.000 blocks.py:2117(get_block_type)\n",
      "        9    0.000    0.000    0.000    0.000 blocks.py:214(mgr_locs)\n",
      "        4    0.000    0.000    0.000    0.000 blocks.py:2158(new_block_2d)\n",
      "       37    0.000    0.000    0.001    0.000 blocks.py:2169(new_block)\n",
      "       37    0.000    0.000    0.000    0.000 blocks.py:2183(check_ndim)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:222(make_block)\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:2247(extend_blocks)\n",
      "        4    0.000    0.000    0.000    0.000 blocks.py:2263(ensure_block_shape)\n",
      "       32    0.000    0.000    0.000    0.000 blocks.py:237(make_block_same_class)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:276(__len__)\n",
      "       22    0.000    0.000    0.000    0.000 blocks.py:501(dtype)\n",
      "        1    0.000    0.000    0.005    0.005 blocks.py:505(astype)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:545(copy)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:822(shape)\n",
      "       27    0.000    0.000    0.000    0.000 blocks.py:826(iget)\n",
      "       32    0.000    0.000    0.047    0.001 blocks.py:860(take_nd)\n",
      "        3    0.000    0.000    0.004    0.001 cast.py:1179(maybe_infer_to_datetimelike)\n",
      "       31    0.000    0.000    0.000    0.000 cast.py:1423(sanitize_to_nanoseconds)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:1764(construct_1d_object_array_from_listlike)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1932(np_can_hold_element)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:509(ensure_dtype_can_hold_na)\n",
      "       45    0.000    0.000    0.000    0.000 cast.py:528(maybe_promote)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:575(_maybe_promote)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:1049(is_numeric_v_string_like)\n",
      "       51    0.000    0.000    0.000    0.000 common.py:1155(needs_i8_conversion)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1205(is_numeric_dtype)\n",
      "       24    0.000    0.000    0.000    0.000 common.py:1247(is_float_dtype)\n",
      "       35    0.000    0.000    0.000    0.000 common.py:1279(is_bool_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1404(is_1d_only_ea_obj)\n",
      "       43    0.000    0.000    0.000    0.000 common.py:1421(is_1d_only_ea_dtype)\n",
      "       51    0.000    0.000    0.000    0.000 common.py:1434(is_extension_array_dtype)\n",
      "       76    0.000    0.000    0.000    0.000 common.py:147(classes)\n",
      "       36    0.000    0.000    0.000    0.000 common.py:1488(is_ea_or_datetimelike_dtype)\n",
      "       76    0.000    0.000    0.000    0.000 common.py:149(<lambda>)\n",
      "       64    0.000    0.000    0.000    0.000 common.py:151(cast_scalar_indexer)\n",
      "       37    0.000    0.000    0.000    0.000 common.py:152(classes_and_not_datetimelike)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:1533(_is_dtype)\n",
      "      108    0.000    0.000    0.000    0.000 common.py:1557(get_dtype)\n",
      "       37    0.000    0.000    0.000    0.000 common.py:157(<lambda>)\n",
      "      113    0.000    0.000    0.000    0.000 common.py:1592(_is_dtype_type)\n",
      "       50    0.000    0.000    0.000    0.000 common.py:163(is_object_dtype)\n",
      "       86    0.000    0.000    0.000    0.000 common.py:1726(validate_all_hashable)\n",
      "      172    0.000    0.000    0.000    0.000 common.py:1745(<genexpr>)\n",
      "       18    0.000    0.000    0.000    0.000 common.py:1752(pandas_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:193(is_sparse)\n",
      "       18    0.000    0.000    0.000    0.000 common.py:235(asarray_tuplesafe)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:293(maybe_iterable_to_list)\n",
      "       30    0.000    0.000    0.000    0.000 common.py:320(is_datetime64_dtype)\n",
      "       50    0.000    0.000    0.000    0.000 common.py:352(apply_if_callable)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:353(is_datetime64tz_dtype)\n",
      "       26    0.000    0.000    0.000    0.000 common.py:394(is_timedelta64_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:428(is_period_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:464(is_interval_dtype)\n",
      "       17    0.000    0.000    0.000    0.000 common.py:502(is_categorical_dtype)\n",
      "       22    0.000    0.000    0.000    0.000 common.py:536(temp_setattr)\n",
      "       33    0.000    0.000    0.000    0.000 common.py:538(is_string_or_object_np_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:545(is_string_dtype)\n",
      "       26    0.000    0.000    0.000    0.000 common.py:556(require_length_match)\n",
      "       10    0.000    0.000    0.066    0.007 common.py:57(new_method)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:574(condition)\n",
      "       35    0.000    0.000    0.000    0.000 common.py:586(is_dtype_equal)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:685(is_integer_dtype)\n",
      "       16    0.000    0.000    0.000    0.000 common.py:737(is_signed_integer_dtype)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:77(get_op_result_name)\n",
      "       16    0.000    0.000    0.000    0.000 common.py:791(is_unsigned_integer_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:930(is_datetime64_ns_dtype)\n",
      "       20    0.000    0.000    0.000    0.000 common.py:96(is_bool_indexer)\n",
      "       39    0.000    0.000    0.000    0.000 config.py:117(_get_single_key)\n",
      "       39    0.000    0.000    0.001    0.000 config.py:135(_get_option)\n",
      "       39    0.000    0.000    0.001    0.000 config.py:263(__call__)\n",
      "       39    0.000    0.000    0.000    0.000 config.py:580(_select_options)\n",
      "       39    0.000    0.000    0.000    0.000 config.py:598(_get_root)\n",
      "       78    0.000    0.000    0.000    0.000 config.py:612(_get_deprecated_option)\n",
      "       39    0.000    0.000    0.000    0.000 config.py:639(_translate_key)\n",
      "       39    0.000    0.000    0.000    0.000 config.py:651(_warn_if_deprecated)\n",
      "       74    0.000    0.000    0.000    0.000 construction.py:400(extract_array)\n",
      "       78    0.000    0.000    0.000    0.000 construction.py:462(ensure_wrapped_if_datetimelike)\n",
      "       28    0.000    0.000    0.005    0.000 construction.py:494(sanitize_array)\n",
      "       28    0.000    0.000    0.000    0.000 construction.py:677(_sanitize_ndim)\n",
      "       26    0.000    0.000    0.000    0.000 construction.py:714(_sanitize_str_dtypes)\n",
      "       28    0.000    0.000    0.000    0.000 construction.py:734(_maybe_repeat)\n",
      "       26    0.000    0.000    0.004    0.000 construction.py:745(_try_cast)\n",
      "       31    0.000    0.000    0.000    0.000 construction.py:862(is_empty_data)\n",
      "        2    0.000    0.000    0.001    0.000 construction.py:882(create_series_with_explicit_dtype)\n",
      "       11    0.000    0.000    0.000    0.000 contextlib.py:112(__enter__)\n",
      "       11    0.000    0.000    0.000    0.000 contextlib.py:121(__exit__)\n",
      "       11    0.000    0.000    0.000    0.000 contextlib.py:242(helper)\n",
      "       11    0.000    0.000    0.000    0.000 contextlib.py:86(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 datetimelike.py:2013(_reso)\n",
      "        2    0.000    0.000    0.000    0.000 datetimelike.py:2139(ensure_arraylike_for_datetimelike)\n",
      "        2    0.000    0.000    0.000    0.000 datetimelike.py:2207(validate_inferred_freq)\n",
      "        2    0.001    0.000    0.001    0.000 datetimelike.py:2244(maybe_infer_freq)\n",
      "        1    0.000    0.000    0.000    0.000 datetimelike.py:296(asi8)\n",
      "        1    0.000    0.000    0.000    0.000 datetimelike.py:561(copy)\n",
      "        1    0.000    0.000    0.000    0.000 datetimelike.py:638(_validate_scalar)\n",
      "        4    0.000    0.000    0.000    0.000 datetimelike.py:927(freq)\n",
      "        1    0.000    0.000    0.020    0.020 datetimes.py:1286(date)\n",
      "        1    0.000    0.000    0.000    0.000 datetimes.py:135(should_cache)\n",
      "        1    0.000    0.000    0.009    0.009 datetimes.py:195(_maybe_cache)\n",
      "        2    0.000    0.000    0.000    0.000 datetimes.py:195(_scalar_type)\n",
      "        2    0.000    0.000    0.000    0.000 datetimes.py:1981(_sequence_to_dt64ns)\n",
      "        1    0.000    0.000    0.000    0.000 datetimes.py:2130(objects_to_datetime64ns)\n",
      "        3    0.000    0.000    0.000    0.000 datetimes.py:2216(maybe_convert_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 datetimes.py:2315(_validate_dt64_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 datetimes.py:2367(validate_tz_from_dtype)\n",
      "        1    0.000    0.000    0.001    0.001 datetimes.py:242(_box_as_indexlike)\n",
      "        2    0.000    0.000    0.000    0.000 datetimes.py:266(_simple_new)\n",
      "        2    0.000    0.000    0.001    0.001 datetimes.py:291(_from_sequence_not_strict)\n",
      "        2    0.000    0.000    0.001    0.001 datetimes.py:314(__new__)\n",
      "        1    0.000    0.000    0.001    0.001 datetimes.py:326(_convert_listlike_datetimes)\n",
      "        1    0.000    0.000    0.000    0.000 datetimes.py:450(_unbox_scalar)\n",
      "        1    0.000    0.000    0.000    0.000 datetimes.py:459(_check_compatible_with)\n",
      "       18    0.000    0.000    0.000    0.000 datetimes.py:496(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 datetimes.py:521(tz)\n",
      "        1    0.000    0.000    0.017    0.017 datetimes.py:706(to_datetime)\n",
      "        1    0.000    0.000    0.000    0.000 datetimes.py:740(_local_timestamps)\n",
      "        2    0.000    0.000    0.000    0.000 datetimes.py:95(tz_to_dtype)\n",
      "       10    0.000    0.000    0.000    0.000 dispatch.py:13(should_extension_dispatch)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:1247(is_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 dtypes.py:977(is_dtype)\n",
      "       15    0.000    0.000    0.000    0.000 enum.py:763(value)\n",
      "        2    0.000    0.000    0.020    0.010 extension.py:70(fget)\n",
      "       82    0.000    0.000    0.000    0.000 flags.py:49(__init__)\n",
      "       65    0.000    0.000    0.000    0.000 flags.py:53(allows_duplicate_labels)\n",
      "       65    0.000    0.000    0.000    0.000 flags.py:85(allows_duplicate_labels)\n",
      "        2    0.000    0.000    0.005    0.002 frame.py:12034(_reindex_for_setitem)\n",
      "        3    0.000    0.000    0.000    0.000 frame.py:1497(__len__)\n",
      "       27    0.000    0.000    0.001    0.000 frame.py:3701(_ixs)\n",
      "       47    0.001    0.000    0.218    0.005 frame.py:3756(__getitem__)\n",
      "       10    0.000    0.000    0.215    0.021 frame.py:3830(_getitem_bool_array)\n",
      "        2    0.000    0.000    0.173    0.087 frame.py:3953(__setitem__)\n",
      "        2    0.000    0.000    0.168    0.084 frame.py:4130(_iset_item_mgr)\n",
      "        2    0.000    0.000    0.168    0.084 frame.py:4137(_set_item_mgr)\n",
      "        2    0.000    0.000    0.173    0.087 frame.py:4162(_set_item)\n",
      "        3    0.000    0.000    0.000    0.000 frame.py:4224(_ensure_valid_index)\n",
      "       27    0.000    0.000    0.001    0.000 frame.py:4247(_box_col_values)\n",
      "        5    0.000    0.000    0.082    0.016 frame.py:4261(_clear_item_cache)\n",
      "       37    0.000    0.000    0.002    0.000 frame.py:4264(_get_item_cache)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:4746(insert)\n",
      "        3    0.000    0.000    0.005    0.002 frame.py:4882(_sanitize_column)\n",
      "       13    0.000    0.000    0.000    0.000 frame.py:599(_constructor)\n",
      "       14    0.000    0.000    0.000    0.000 frame.py:608(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 frame.py:6120(reset_index)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:6854(sort_values)\n",
      "       11    0.000    0.000    0.003    0.000 frame.py:8257(groupby)\n",
      "       12    0.000    0.000    0.000    0.000 frame.py:856(axes)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:1021(_argsort_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:1025(argsort)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:1764(_ravel_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:1768(ravel)\n",
      "       11    0.000    0.000    0.000    0.000 fromnumeric.py:1877(_nonzero_dispatcher)\n",
      "       11    0.000    0.000    0.000    0.000 fromnumeric.py:1881(nonzero)\n",
      "       12    0.000    0.000    0.000    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "        4    0.000    0.000    0.000    0.000 function_base.py:5168(_delete_dispatcher)\n",
      "        4    0.079    0.020    0.086    0.022 function_base.py:5172(delete)\n",
      "        1    0.000    0.000    0.000    0.000 function_base.py:5364(_insert_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 function_base.py:5368(insert)\n",
      "        2    0.000    0.000    0.000    0.000 function_base.py:5558(_append_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 function_base.py:5562(append)\n",
      "       11    0.000    0.000    0.001    0.000 generic.py:1397(__getitem__)\n",
      "       11    0.000    0.000    0.000    0.000 generic.py:1413(_gotitem)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1698(_is_label_reference)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:1720(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:1725(<genexpr>)\n",
      "       11    0.000    0.000    0.000    0.000 generic.py:1753(_check_label_or_level_ambiguity)\n",
      "       11    0.000    0.000    0.000    0.000 generic.py:1774(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1798(_get_label_or_level_values)\n",
      "       11    0.000    0.000    0.000    0.000 generic.py:180(_wrap_agged_manager)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1834(<listcomp>)\n",
      "       11    0.000    0.000    0.000    0.000 generic.py:191(_get_data_to_aggregate)\n",
      "       22    0.000    0.000    0.000    0.000 generic.py:1996(__contains__)\n",
      "       82    0.001    0.000    0.001    0.000 generic.py:260(__init__)\n",
      "       65    0.000    0.000    0.000    0.000 generic.py:333(attrs)\n",
      "      130    0.000    0.000    0.000    0.000 generic.py:354(flags)\n",
      "       10    0.000    0.000    0.212    0.021 generic.py:3874(_take)\n",
      "       10    0.000    0.000    0.213    0.021 generic.py:3895(_take_with_is_copy)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:3909(xs)\n",
      "      786    0.000    0.000    0.000    0.000 generic.py:40(_check)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:4098(_slice)\n",
      "       11    0.000    0.000    0.000    0.000 generic.py:4115(_set_is_copy)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:4138(_check_setitem_copy)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:4260(_check_inplace_and_allows_duplicate_labels)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:446(_validate_dtype)\n",
      "      786    0.000    0.000    0.001    0.000 generic.py:45(_instancecheck)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:5479(head)\n",
      "      103    0.000    0.000    0.000    0.000 generic.py:551(_get_axis_number)\n",
      "       33    0.000    0.000    0.000    0.000 generic.py:565(_get_axis)\n",
      "       12    0.000    0.000    0.000    0.000 generic.py:571(_get_block_manager_axis)\n",
      "       65    0.001    0.000    0.001    0.000 generic.py:5849(__finalize__)\n",
      "       61    0.000    0.000    0.000    0.000 generic.py:5893(__getattr__)\n",
      "      139    0.039    0.000    0.040    0.000 generic.py:5909(__setattr__)\n",
      "       10    0.000    0.000    0.162    0.016 generic.py:5964(_protect_consolidate)\n",
      "       10    0.000    0.000    0.162    0.016 generic.py:5978(_consolidate_inplace)\n",
      "       10    0.000    0.000    0.162    0.016 generic.py:5982(f)\n",
      "        1    0.000    0.000    0.006    0.006 generic.py:6081(astype)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:6263(copy)\n",
      "       24    0.000    0.000    0.000    0.000 generic.py:641(_info_axis)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:820(_set_axis)\n",
      "       11    0.001    0.000    0.079    0.007 groupby.py:2035(count)\n",
      "       11    0.000    0.000    0.001    0.000 groupby.py:2053(hfunc)\n",
      "       11    0.000    0.000    0.000    0.000 groupby.py:4067(_reindex_output)\n",
      "       22    0.000    0.000    0.003    0.000 groupby.py:916(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 groupby.py:975(__getattr__)\n",
      "  352/286    0.000    0.000    0.000    0.000 groupby.py:985(__getattribute__)\n",
      "       11    0.000    0.000    0.000    0.000 grouper.py:468(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 grouper.py:570(name)\n",
      "       11    0.000    0.000    0.000    0.000 grouper.py:588(_ilevel)\n",
      "       11    0.000    0.000    0.073    0.007 grouper.py:616(codes)\n",
      "       11    0.000    0.000    0.000    0.000 grouper.py:640(result_index)\n",
      "       11    0.000    0.000    0.002    0.000 grouper.py:650(group_index)\n",
      "       11    0.000    0.000    0.073    0.007 grouper.py:659(_codes_and_uniques)\n",
      "       11    0.000    0.000    0.002    0.000 grouper.py:703(get_grouper)\n",
      "       22    0.000    0.000    0.000    0.000 grouper.py:805(<genexpr>)\n",
      "       22    0.000    0.000    0.000    0.000 grouper.py:806(<genexpr>)\n",
      "       22    0.000    0.000    0.000    0.000 grouper.py:807(<genexpr>)\n",
      "       10    0.000    0.000    0.000    0.000 grouper.py:841(is_in_axis)\n",
      "       11    0.000    0.000    0.000    0.000 grouper.py:858(is_in_obj)\n",
      "       10    0.000    0.000    0.000    0.000 grouper.py:928(_is_label_like)\n",
      "       11    0.000    0.000    0.000    0.000 grouper.py:932(_convert_grouper)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:1060(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:140(iloc)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:1593(_getitem_axis)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:1630(_get_slice_axis)\n",
      "       12    0.000    0.000    0.000    0.000 indexing.py:2484(convert_to_index_sliceable)\n",
      "       10    0.000    0.000    0.001    0.000 indexing.py:2518(check_bool_indexer)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:2639(need_slice)\n",
      "       48    0.000    0.000    0.000    0.000 indexing.py:2652(check_deprecated_indexers)\n",
      "       44    0.000    0.000    0.000    0.000 inference.py:189(is_array_like)\n",
      "       30    0.000    0.000    0.000    0.000 inference.py:267(is_dict_like)\n",
      "       93    0.000    0.000    0.000    0.000 inference.py:293(<genexpr>)\n",
      "      196    0.000    0.000    0.000    0.000 inference.py:326(is_hashable)\n",
      "        1    0.000    0.000    0.000    0.000 inference.py:364(is_sequence)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:73(isclass)\n",
      "       12    0.000    0.000    0.000    0.000 managers.py:1051(from_blocks)\n",
      "       27    0.000    0.000    0.000    0.000 managers.py:1117(iget)\n",
      "        2    0.000    0.000    0.087    0.044 managers.py:1169(iset)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1226(value_getitem)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1373(insert)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1414(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1424(_insert_update_mgr_locs)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1434(_insert_update_blklocs_and_blknos)\n",
      "       43    0.000    0.000    0.000    0.000 managers.py:170(blknos)\n",
      "       12    0.000    0.000    0.000    0.000 managers.py:1823(is_consolidated)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1831(_consolidate_check)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1837(<listcomp>)\n",
      "        2    0.000    0.000    0.123    0.062 managers.py:1841(_consolidate_inplace)\n",
      "       22    0.000    0.000    0.000    0.000 managers.py:1859(ndim)\n",
      "       41    0.000    0.000    0.000    0.000 managers.py:186(blklocs)\n",
      "       64    0.000    0.000    0.000    0.000 managers.py:1868(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1892(from_blocks)\n",
      "       36    0.000    0.000    0.001    0.000 managers.py:1908(from_array)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1916(to_2d_mgr)\n",
      "       41    0.000    0.000    0.000    0.000 managers.py:1980(_block)\n",
      "       83    0.000    0.000    0.000    0.000 managers.py:2027(dtype)\n",
      "       64    0.000    0.000    0.000    0.000 managers.py:2038(internal_values)\n",
      "       41    0.000    0.000    0.000    0.000 managers.py:226(set_axis)\n",
      "        1    0.000    0.000    0.123    0.123 managers.py:2286(_consolidate)\n",
      "       10    0.000    0.000    0.000    0.000 managers.py:2291(<lambda>)\n",
      "        3    0.079    0.026    0.123    0.041 managers.py:2328(_merge_blocks)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:2339(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:2348(<listcomp>)\n",
      "       16    0.000    0.000    0.000    0.000 managers.py:236(items)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:2365(_fast_count_smallints)\n",
      "       12    0.000    0.000    0.000    0.000 managers.py:2397(_using_copy_on_write)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:260(_clear_reference_block)\n",
      "       11    0.000    0.000    0.000    0.000 managers.py:271(arrays)\n",
      "       11    0.000    0.000    0.000    0.000 managers.py:283(<listcomp>)\n",
      "        2    0.000    0.000    0.005    0.003 managers.py:297(apply)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:326(<dictcomp>)\n",
      "        1    0.000    0.000    0.005    0.005 managers.py:445(astype)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:612(copy)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:638(copy_func)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:641(<listcomp>)\n",
      "       10    0.000    0.000    0.123    0.012 managers.py:666(consolidate)\n",
      "       11    0.000    0.000    0.048    0.004 managers.py:682(reindex_indexer)\n",
      "       11    0.000    0.000    0.047    0.004 managers.py:743(<listcomp>)\n",
      "       11    0.000    0.000    0.050    0.005 managers.py:935(take)\n",
      "       15    0.000    0.000    0.000    0.000 managers.py:988(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:107(clean_fill_method)\n",
      "       47    0.000    0.000    0.012    0.000 missing.py:108(isna)\n",
      "       47    0.000    0.000    0.012    0.000 missing.py:191(_isna)\n",
      "       33    0.000    0.000    0.012    0.000 missing.py:268(_isna_array)\n",
      "       11    0.000    0.000    0.012    0.001 missing.py:309(_isna_string_dtype)\n",
      "       11    0.000    0.000    0.000    0.000 missing.py:460(array_equivalent)\n",
      "        6    0.000    0.000    0.000    0.000 missing.py:641(na_value_for_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 missing.py:695(is_valid_na_for_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:910(clean_reindex_fill_method)\n",
      "       33    0.000    0.000    0.000    0.000 multiarray.py:1080(copyto)\n",
      "       17    0.000    0.000    0.000    0.000 multiarray.py:153(concatenate)\n",
      "        1    0.000    0.000    0.000    0.000 multiarray.py:892(bincount)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:1330(normalize_axis_tuple)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:1380(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:1389(_moveaxis_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:1393(moveaxis)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:1455(<listcomp>)\n",
      "       33    0.000    0.000    0.000    0.000 numeric.py:274(full)\n",
      "       11    0.000    0.000    0.000    0.000 ops.py:742(__init__)\n",
      "       66    0.000    0.000    0.000    0.000 ops.py:762(groupings)\n",
      "       11    0.000    0.000    0.000    0.000 ops.py:904(names)\n",
      "       11    0.000    0.000    0.000    0.000 ops.py:906(<listcomp>)\n",
      "       11    0.000    0.000    0.076    0.007 ops.py:945(group_info)\n",
      "       11    0.000    0.000    0.076    0.007 ops.py:967(_get_compressed_codes)\n",
      "       11    0.000    0.000    0.000    0.000 ops.py:991(result_index)\n",
      "       12    0.000    0.000    0.000    0.000 range.py:174(_simple_new)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:190(_constructor)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:196(_data)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:248(start)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:271(stop)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:294(step)\n",
      "       11    0.000    0.000    0.000    0.000 range.py:354(dtype)\n",
      "       23    0.000    0.000    0.000    0.000 range.py:542(equals)\n",
      "      131    0.000    0.000    0.000    0.000 range.py:947(__len__)\n",
      "       15    0.000    0.000    0.000    0.000 re.py:250(compile)\n",
      "       15    0.000    0.000    0.000    0.000 re.py:289(_compile)\n",
      "       27    0.000    0.000    0.000    0.000 series.py:1270(_set_as_cached)\n",
      "        1    0.000    0.000    0.001    0.001 series.py:1431(reset_index)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:1900(to_frame)\n",
      "       10    0.000    0.000    0.002    0.000 series.py:3197(_construct_result)\n",
      "    68/67    0.001    0.000    0.009    0.000 series.py:343(__init__)\n",
      "       10    0.000    0.000    0.006    0.001 series.py:3576(sort_values)\n",
      "        1    0.000    0.000    0.008    0.008 series.py:4463(map)\n",
      "        1    0.000    0.000    0.070    0.070 series.py:4664(apply)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:487(_init_dict)\n",
      "       34    0.000    0.000    0.000    0.000 series.py:547(_constructor)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:551(_constructor_expanddim)\n",
      "       40    0.000    0.000    0.001    0.000 series.py:566(_set_axis)\n",
      "       83    0.000    0.000    0.000    0.000 series.py:597(dtype)\n",
      "      116    0.000    0.000    0.000    0.000 series.py:612(name)\n",
      "       10    0.000    0.000    0.066    0.007 series.py:6236(_cmp_method)\n",
      "       75    0.000    0.000    0.000    0.000 series.py:662(name)\n",
      "       64    0.000    0.000    0.000    0.000 series.py:709(_values)\n",
      "       14    0.000    0.000    0.000    0.000 series.py:765(__len__)\n",
      "       10    0.000    0.000    0.000    0.000 series.py:847(__array__)\n",
      "        1    0.000    0.000    0.000    0.000 shape_base.py:207(_arrays_for_stack_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 shape_base.py:215(_vhstack_dispatcher)\n",
      "        1    0.043    0.043    0.043    0.043 shape_base.py:219(vstack)\n",
      "        1    0.000    0.000    0.000    0.000 shape_base.py:77(_atleast_2d_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 shape_base.py:81(atleast_2d)\n",
      "       11    0.000    0.000    0.001    0.000 sorting.py:376(nargsort)\n",
      "       44    0.000    0.000    0.048    0.001 take.py:120(_take_nd_ndarray)\n",
      "       44    0.000    0.000    0.000    0.000 take.py:326(_get_take_nd_function)\n",
      "        1    0.000    0.000    0.000    0.000 take.py:350(wrapper)\n",
      "       44    0.000    0.000    0.000    0.000 take.py:554(_take_preprocess_indexer_and_fill_value)\n",
      "    45/44    0.000    0.000    0.048    0.001 take.py:57(take_nd)\n",
      "       15    0.000    0.000    0.000    0.000 types.py:171(__get__)\n",
      "       72    0.000    0.000    0.000    0.000 typing.py:1333(cast)\n",
      "       11    0.000    0.000    0.000    0.000 typing.py:702(__instancecheck__)\n",
      "       11    0.000    0.000    0.000    0.000 typing.py:831(__subclasscheck__)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:192(validate_indices)\n",
      "       11    0.001    0.000    0.001    0.000 utils.py:244(maybe_convert_indices)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:431(check_array_indexer)\n",
      "       15    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\n",
      "       15    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\n",
      "       15    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\n",
      "       15    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\n",
      "       15    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\n",
      "       65    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x00007FFBC63D5C60}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _simple_new}\n",
      "       45    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
      "      117    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "       34    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "       63    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000    0.689    0.689 {built-in method builtins.exec}\n",
      "1021/1019    0.000    0.000    0.020    0.000 {built-in method builtins.getattr}\n",
      "      223    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "      261    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "3751/3688    0.001    0.000    0.002    0.000 {built-in method builtins.isinstance}\n",
      "      302    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      " 1043/783    0.000    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "       22    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "       22    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "       27    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "       29    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "  203/193    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      "       84    0.013    0.000    0.013    0.000 {built-in method numpy.empty}\n",
      "       44    0.000    0.000    0.000    0.000 {built-in method numpy.geterrobj}\n",
      "       22    0.000    0.000    0.000    0.000 {built-in method numpy.seterrobj}\n",
      "       23    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_datetime_array}\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method pandas._libs.missing.checknull}\n",
      "       11    0.012    0.001    0.012    0.001 {built-in method pandas._libs.missing.isnaobj}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.tslib.array_to_datetime}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method pandas._libs.tslibs.offsets.to_offset}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method pandas._libs.tslibs.timezones.maybe_get_tz}\n",
      "        1    0.000    0.000    0.000    0.000 {function DatetimeLikeArrayMixin.copy at 0x0000016200736A60}\n",
      "        1    0.000    0.000    0.000    0.000 {method '_from_backing_data' of 'pandas._libs.arrays.NDArrayBacked' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method '_rebuild_blknos_and_blklocs' of 'pandas._libs.internals.BlockManager' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "       43    0.000    0.000    0.001    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "       35    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'append' of 'pandas._libs.internals.BlockPlacement' objects}\n",
      "       34    0.019    0.001    0.019    0.001 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "       25    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        5    0.082    0.016    0.082    0.016 {method 'clear' of 'dict' objects}\n",
      "       29    0.010    0.000    0.010    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'delete' of 'pandas._libs.internals.BlockPlacement' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.009    0.009    0.009    0.009 {method 'factorize' of 'pandas._libs.hashtable.PyObjectHashTable' objects}\n",
      "       10    0.019    0.002    0.019    0.002 {method 'factorize' of 'pandas._libs.hashtable.StringHashTable' objects}\n",
      "       37    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.005    0.005    0.005    0.005 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
      "       29    0.000    0.000    0.000    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'get_slice' of 'pandas._libs.internals.BlockManager' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'increment_above' of 'pandas._libs.internals.BlockPlacement' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'min' of 'numpy.ndarray' objects}\n",
      "       22    0.001    0.000    0.001    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "       13    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "       45    0.001    0.000    0.001    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "       15    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "       26    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "       39    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "       22    0.002    0.000    0.002    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "        1    0.004    0.004    0.004    0.004 {method 'unique' of 'pandas._libs.hashtable.PyObjectHashTable' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "       39    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
      "      111    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\n",
      "       12    0.001    0.000    0.001    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
      "       10    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis0_int64_int64}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis0_object_object}\n",
      "       10    0.001    0.000    0.001    0.000 {pandas._libs.algos.take_2d_axis1_int64_int64}\n",
      "       10    0.039    0.004    0.039    0.004 {pandas._libs.algos.take_2d_axis1_object_object}\n",
      "        2    0.000    0.000    0.000    0.000 {pandas._libs.internals.get_blkno_placements}\n",
      "       11    0.001    0.000    0.001    0.000 {pandas._libs.lib.count_level_2d}\n",
      "        3    0.003    0.001    0.003    0.001 {pandas._libs.lib.infer_datetimelike_array}\n",
      "       25    0.011    0.000    0.011    0.000 {pandas._libs.lib.infer_dtype}\n",
      "       25    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool}\n",
      "       74    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\n",
      "       77    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
      "       42    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
      "      213    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
      "       78    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
      "       68    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "        1    0.032    0.032    0.060    0.060 {pandas._libs.lib.map_infer}\n",
      "       32    0.001    0.000    0.002    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
      "       10    0.063    0.006    0.063    0.006 {pandas._libs.ops.scalar_compare}\n",
      "        2    0.000    0.000    0.000    0.000 {pandas._libs.tslibs.np_datetime.is_unitless}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.tslibs.np_datetime.py_get_unit_from_dtype}\n",
      "        1    0.020    0.020    0.020    0.020 {pandas._libs.tslibs.vectorized.ints_to_pydatetime}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### TIEMPO DE EJECUCIÓN q1_time ####\n",
    "cProfile.run(\"q1_time(file_path)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEMORIA:\n",
    "Para evaluar el uso de memoria de la función, se colocó el indicador @profile al comienzo de la función y se corrió desde la terminal de la siguiente forma: python -m memory_profiler q1_time.py. Lo anterior arrojó el siguiente resultado:\n",
    "\n",
    "          \n",
    "     Line #   Mem usage    Increment  Occurrences   Line Contents\n",
    "          \n",
    "\n",
    "          8 1505.211 MiB 1505.211 MiB           1   @profile\n",
    "          9                                         def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "          10                                             # Cargar el archivo JSON en un DataFrame de Pandas\n",
    "          11\n",
    "          12                                             # Extraer el 'username' de la columna 'user'\n",
    "          13 1507.539 MiB    2.328 MiB      234815       df['username'] = df['user'].apply(lambda user: user['username'])\n",
    "          14\n",
    "          15                                             # Convertir la columna 'date' a datetime.date\n",
    "          16 1512.254 MiB    4.715 MiB           1       df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "          17\n",
    "          18                                             # Agrupar por fecha y contar los tweets\n",
    "          19 1513.621 MiB    1.367 MiB           1       tweet_counts = df.groupby(df['date'])['id'].count().reset_index()\n",
    "          20\n",
    "          21                                             # Ordenar por el conteo de tweets descendente y obtener las 10 fechas principales\n",
    "          22 1513.688 MiB    0.066 MiB           1       top_dates = tweet_counts.sort_values('id', ascending=False).head(10)['date'].tolist()\n",
    "          23\n",
    "          24                                             # Encontrar el usuario con más tweets para cada fecha principal\n",
    "          25 1513.688 MiB    0.000 MiB           1       top_users = []\n",
    "          26 1521.445 MiB   -0.035 MiB          11       for date in top_dates:\n",
    "          27 1521.379 MiB    6.562 MiB          10           date_df = df[df['date'] == date]\n",
    "          28 1521.445 MiB    1.148 MiB          10           top_user = date_df.groupby('username')['id'].count().sort_values(ascending=False).index[0]\n",
    "          29 1521.445 MiB   -0.035 MiB          10           top_users.append((date, top_user))\n",
    "          30\n",
    "          31 1521.445 MiB    0.000 MiB           1       return top_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización de memoria en uso**\n",
    "\n",
    "Explicación de q1_memory:\n",
    "\n",
    "1.   Lectura Línea por Línea: En este enfoque, se lee el archivo JSON línea por línea en lugar de cargarlo completo en la memoria. Esto reduce significativamente el uso de memoria, ya que no se carga todo el archivo en la memoria al mismo tiempo.\n",
    "\n",
    "2.  Uso de Estructuras de Datos Eficientes: Se utilizan estructuras de datos eficientes como Counter y defaultdict para contar los tweets por fecha y por usuario. Estas estructuras de datos están optimizadas para minimizar el uso de memoria y ofrecen un rendimiento eficiente para el conteo de elementos.\n",
    "\n",
    "3.   Reducción de Datos Intermedios: En lugar de almacenar todos los datos en memoria, se calculan y almacenan solo los datos necesarios, como los conteos de tweets por fecha y por usuario. Esto reduce la cantidad de memoria necesaria para almacenar datos intermedios.\n",
    "\n",
    "Por qué es Bueno para Optimizar la Memoria en Uso:\n",
    "\n",
    "-   La lectura línea por línea del archivo y el procesamiento de datos en tiempo real reducen significativamente la cantidad de memoria necesaria, ya que no es necesario cargar todo el archivo en la memoria al mismo tiempo.\n",
    "\n",
    "-   El uso de estructuras de datos eficientes como Counter y defaultdict minimiza el uso de memoria al almacenar solo la información necesaria para realizar los cálculos requeridos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory\n",
    "result = q1_memory(file_path=file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1560148 function calls in 4.839 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.003    0.003    4.839    4.839 <string>:1(<module>)\n",
      "   117407    0.099    0.000    2.821    0.000 __init__.py:299(loads)\n",
      "       14    0.000    0.000    0.000    0.000 __init__.py:581(__init__)\n",
      "    51659    0.005    0.000    0.005    0.000 __init__.py:595(__missing__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:600(most_common)\n",
      "       14    0.000    0.000    0.000    0.000 __init__.py:649(update)\n",
      "        1    0.000    0.000    0.000    0.000 _bootlocale.py:11(getpreferredencoding)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "    49772    0.023    0.000    0.584    0.000 cp1252.py:22(decode)\n",
      "   117407    0.143    0.000    2.693    0.000 decoder.py:332(decode)\n",
      "   117407    2.433    0.000    2.433    0.000 decoder.py:343(raw_decode)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:521(nlargest)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:563(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:577(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 q1_memory.py:31(<listcomp>)\n",
      "        1    0.000    0.000    0.006    0.006 q1_memory.py:34(<listcomp>)\n",
      "        1    1.379    1.379    4.835    4.835 q1_memory.py:8(q1_memory)\n",
      "    49772    0.561    0.000    0.561    0.000 {built-in method _codecs.charmap_decode}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _heapq.heapify}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _heapq.heapreplace}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _locale._getdefaultlocale}\n",
      "        1    0.000    0.000    4.839    4.839 {built-in method builtins.exec}\n",
      "   117407    0.009    0.000    0.009    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "   117408    0.012    0.000    0.012    0.000 {built-in method builtins.len}\n",
      "       10    0.006    0.001    0.006    0.001 {built-in method builtins.max}\n",
      "   117407    0.026    0.000    0.026    0.000 {built-in method fromisoformat}\n",
      "        1    0.001    0.001    0.001    0.001 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "   117407    0.014    0.000    0.014    0.000 {method 'date' of 'datetime.datetime' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   234814    0.020    0.000    0.020    0.000 {method 'end' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "   234814    0.085    0.000    0.085    0.000 {method 'match' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "   117407    0.020    0.000    0.020    0.000 {method 'startswith' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"q1_memory(file_path)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEMORIA:\n",
    "Para evaluar el uso de memoria de la función, se colocó el indicador @profile al comienzo de la función y se corrió desde la terminal de la siguiente forma: python -m memory_profiler q1_memory.py. Lo anterior arrojó el siguiente resultado:\n",
    "\n",
    "    Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "    =============================================================\n",
    "        8   41.039 MiB   41.039 MiB           1   @profile\n",
    "        9                                         def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "        10   41.051 MiB    0.012 MiB           1       tweet_counts = Counter()\n",
    "        11   41.051 MiB    0.000 MiB           1       user_counts = defaultdict(Counter)\n",
    "        12\n",
    "        13   41.051 MiB    0.000 MiB           1       with open(file_path, 'r') as f:\n",
    "        14   47.750 MiB    2.016 MiB      117408           for line in f:\n",
    "        15   47.750 MiB    2.879 MiB      117407               tweet = json.loads(line)\n",
    "        16   47.750 MiB    0.379 MiB      117407               date = datetime.datetime.fromisoformat(tweet['date']).date()\n",
    "        17   47.750 MiB    0.000 MiB      117407               user = tweet['user']['username']\n",
    "        18\n",
    "        19   47.750 MiB    0.000 MiB      117407               tweet_counts[date] += 1\n",
    "        20   47.750 MiB    1.426 MiB      117407               user_counts[date][user] += 1\n",
    "        21\n",
    "        22   47.750 MiB    0.000 MiB          13       top_dates = [date for date, count in tweet_counts.most_common(10)]\n",
    "        23   47.750 MiB    0.000 MiB          13       top_users = [(date, max(user_counts[date], key=user_counts[date].get)) for date in top_dates]\n",
    "        24\n",
    "        25   47.750 MiB    0.000 MiB           1       return top_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discusión resultados:**\n",
    "\n",
    "La comparación entre `q1_time` y `q1_memory` revela diferencias significativas tanto en el tiempo de ejecución como en el uso de memoria. \n",
    "\n",
    "Para `q1_time`, que se enfoca en la optimización del tiempo de ejecución, se utilizó la biblioteca `pandas` para cargar el archivo JSON en un DataFrame, lo que permitió realizar operaciones de procesamiento de datos de manera eficiente. Sin embargo, esto resultó en un mayor uso de memoria debido a la carga completa del conjunto de datos en memoria. A pesar de esto, la ejecución fue más rápida, con un tiempo total de 0.634 segundos. \n",
    "\n",
    "En contraste, `q1_memory` se diseñó para optimizar el uso de memoria. En esta función, se evitó cargar el conjunto de datos completo en memoria y, en su lugar, se procesaron los datos línea por línea de manera incremental. Aunque esta estrategia resultó en un tiempo de ejecución más largo de 4.839 segundos, se logró un uso de memoria considerablemente menor, con solo 47.750 MiB utilizados respecto a los 1521.445 MiB de q1_time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Los top 10 emojis más usados con su respectivo conteo. Debe incluir las siguientes funciones:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización tiempo de ejecución**\n",
    "\n",
    "\n",
    "1. Importamos las librerías necesarias: typing para definir los tipos de las variables de entrada y salida, pandas para leer el archivo JSON y convertirlo en un DataFrame, emoji para analizar el texto y obtener los emojis, y collections para contar los emojis.\n",
    "2. Definimos la función q2_time que toma como entrada un archivo JSON y devuelve una lista de tuplas, donde cada tupla contiene un emoji y su frecuencia en el archivo JSON.\n",
    "3. Leemos el archivo JSON en un DataFrame de Pandas.\n",
    "4. Concatenamos todos los tweets en un solo string separados por un espacio en blanco.\n",
    "5. Usamos el método emoji_list de la librería emoji para analizar el string y obtener todos los emojis presentes. El método emoji_list devuelve una lista de diccionarios, donde cada diccionario contiene información sobre un emoji, incluyendo el emoji en sí.\n",
    "6. Extraemos el valor de la clave emoji de cada diccionario en la lista y lo agregamos a la lista emojis.\n",
    "7. Contamos los emojis en la lista emojis usando el método Counter de la librería collections.\n",
    "8. Devolvemos los 10 emojis más utilizados usando el método most_common de la instancia Counter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('🙏', 5049), ('😂', 3072), ('🚜', 2972), ('🌾', 2182), ('🇮🇳', 2086), ('🤣', 1668), ('✊', 1651), ('❤️', 1382), ('🙏🏻', 1317), ('💚', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "from emoji import emoji_list\n",
    "from collections import Counter\n",
    "#file_path = \"farmers-protest-tweets-2021-2-4.json\"\n",
    "\n",
    "\n",
    "\n",
    "#@profile\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Leer el archivo JSON en un DataFrame de Pandas\n",
    "    #df = pd.read_json(file_path, lines=True)\n",
    "    \n",
    "    # Obtener un solo string que contenga todos los contenidos de los tweets\n",
    "    single_string = df['content'].str.cat(sep=' ')\n",
    "    \n",
    "    # Usar el método emoji_list para analizar el string y obtener todos los emojis presentes\n",
    "    emojis = [emoji['emoji'] for emoji in emoji_list(single_string)]\n",
    "    \n",
    "    # Contar los emojis y devolver los 10 más utilizados\n",
    "    return Counter(emojis).most_common(10)\n",
    "\n",
    "print(q2_time(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         85746551 function calls in 24.301 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000   24.294   24.294 1638560488.py:10(q2_time)\n",
      "        1    0.018    0.018    0.018    0.018 1638560488.py:18(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1033(_handle_fromlist)\n",
      " 17140708    2.866    0.000    5.161    0.000 <string>:1(<lambda>)\n",
      "        1    0.007    0.007   24.301   24.301 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.007    0.007 __init__.py:581(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:600(most_common)\n",
      "        1    0.000    0.000    0.007    0.007 __init__.py:649(update)\n",
      "        1    0.000    0.000    0.000    0.000 _methods.py:55(_any)\n",
      "        1    0.000    0.000    0.000    0.000 abc.py:96(__instancecheck__)\n",
      "        1    0.003    0.003    0.092    0.092 accessor.py:122(wrapper)\n",
      "        1    0.000    0.000    0.089    0.089 accessor.py:427(cat)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5292(__contains__)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:352(apply_if_callable)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:538(is_string_or_object_np_dtype)\n",
      "        1    0.000    0.000   24.176   24.176 core.py:283(emoji_list)\n",
      "        1    4.358    4.358   24.176   24.176 core.py:290(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:3756(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:4264(_get_item_cache)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:40(_check)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:45(_instancecheck)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:5893(__getattr__)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:521(nlargest)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:563(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:577(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:2652(check_deprecated_indexers)\n",
      "        1    0.000    0.000    0.000    0.000 inference.py:326(is_hashable)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:2038(internal_values)\n",
      "        1    0.000    0.000    0.019    0.019 missing.py:108(isna)\n",
      "        1    0.000    0.000    0.019    0.019 missing.py:191(_isna)\n",
      "        1    0.000    0.000    0.019    0.019 missing.py:268(_isna_array)\n",
      "        1    0.000    0.000    0.019    0.019 missing.py:309(_isna_string_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:709(_values)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:847(__array__)\n",
      " 17140706   12.231    0.000   18.585    0.000 tokenizer.py:158(tokenize)\n",
      "    42922    0.012    0.000    0.012    0.000 tokenizer.py:29(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 tokenizer.py:301(get_search_tree)\n",
      " 17140708    2.296    0.000    2.296    0.000 {built-in method __new__ of type object at 0x00007FFBC63D5C60}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        1    0.007    0.007    0.007    0.007 {built-in method _collections._count_elements}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _heapq.heapify}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _heapq.heapreplace}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000   24.301   24.301 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      " 17140720    1.233    0.000    1.233    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\n",
      "        1    0.018    0.018    0.018    0.018 {built-in method pandas._libs.missing.isnaobj}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      " 17140711    1.180    0.000    1.180    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.064    0.064    0.064    0.064 {method 'join' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "        1    0.006    0.006    0.006    0.006 {pandas._libs.algos.ensure_object}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### TIEMPO DE EJECUCIÓN q2_time ####\n",
    "cProfile.run(\"q2_time(file_path)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memoria:\n",
    "\n",
    "    Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "    =============================================================\n",
    "        10 1512.516 MiB 1512.516 MiB           1   @profile\n",
    "        11                                         def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "        12                                             # Leer el archivo JSON en un DataFrame de Pandas\n",
    "        13                                             #\n",
    "        14\n",
    "        15                                             # Obtener un solo string que contenga todos los contenidos de los tweets\n",
    "        16 1579.945 MiB   67.430 MiB           1       single_string = df['content'].str.cat(sep=' ')\n",
    "        17\n",
    "        18                                             # Usar el método emoji_list para analizar el string y obtener todos los emojis presentes\n",
    "        19 1593.645 MiB   12.777 MiB       42925       emojis = [emoji['emoji'] for emoji in emoji_list(single_string)]\n",
    "        20\n",
    "        21                                             # Contar los emojis y devolver los 10 más utilizados\n",
    "        22 1593.184 MiB   -0.461 MiB           1       return Counter(emojis).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización memoria en uso**\n",
    "\n",
    "\n",
    "1. En lugar de leer todo el archivo JSON en memoria y convertirlo en un DataFrame, leemos el archivo línea por línea usando un bucle for. Esto significa que solo necesitamos tener una línea del archivo en memoria a la vez, en lugar de cargar todo el archivo en memoria al mismo tiempo.\n",
    "2. En lugar de crear una cadena grande que contenga todos los tweets, iteramos sobre cada tweet y lo procesamos individualmente. Esto significa que solo necesitamos mantener un tweet en memoria a la vez, en lugar de crear una gran cadena que contenga todos los tweets.\n",
    "3. En lugar de usar la función emoji_list para analizar toda la cadena de tweets a la vez, analizamos cada tweet individualmente usando el mismo método. Esto significa que solo necesitamos mantener un tweet en memoria a la vez, en lugar de crear una gran lista que contenga todos los emojis de todos los tweets.\n",
    "4. Usamos el método update del contador emoji_counts para actualizar el contador con los emojis de cada tweet. Esto significa que no necesitamos crear una nueva lista de emojis para cada tweet, sino que podemos actualizar el contador en el lugar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('🙏', 5049), ('😂', 3072), ('🚜', 2972), ('🌾', 2182), ('🇮🇳', 2086), ('🤣', 1668), ('✊', 1651), ('❤️', 1382), ('🙏🏻', 1317), ('💚', 1040)]\n"
     ]
    }
   ],
   "source": [
    "from q2_memory import q2_memory\n",
    "result = q2_memory(file_path=file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         87724551 function calls in 36.425 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   117407    0.027    0.000    0.027    0.000 3127824189.py:14(<listcomp>)\n",
      "        1    2.284    2.284   36.425   36.425 3127824189.py:5(q2_memory)\n",
      " 17023302    3.484    0.000    6.248    0.000 <string>:1(<lambda>)\n",
      "        1    0.000    0.000   36.425   36.425 <string>:1(<module>)\n",
      "   117407    0.158    0.000    4.050    0.000 __init__.py:299(loads)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:581(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:600(most_common)\n",
      "   117408    0.093    0.000    0.324    0.000 __init__.py:649(update)\n",
      "        1    0.000    0.000    0.000    0.000 _bootlocale.py:11(getpreferredencoding)\n",
      "   117407    0.042    0.000    0.106    0.000 abc.py:96(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "   117407    0.117    0.000   28.994    0.000 core.py:283(emoji_list)\n",
      "   117407    4.842    0.000   28.877    0.000 core.py:290(<listcomp>)\n",
      "    49772    0.049    0.000    0.746    0.000 cp1252.py:22(decode)\n",
      "   117407    0.232    0.000    3.840    0.000 decoder.py:332(decode)\n",
      "   117407    3.419    0.000    3.419    0.000 decoder.py:343(raw_decode)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:521(nlargest)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:563(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:577(<listcomp>)\n",
      " 17140706   14.728    0.000   22.474    0.000 tokenizer.py:158(tokenize)\n",
      "    42922    0.020    0.000    0.020    0.000 tokenizer.py:29(__init__)\n",
      "   117407    0.022    0.000    0.022    0.000 tokenizer.py:301(get_search_tree)\n",
      " 17023302    2.763    0.000    2.763    0.000 {built-in method __new__ of type object at 0x00007FFC06A05C60}\n",
      "   117407    0.064    0.000    0.064    0.000 {built-in method _abc._abc_instancecheck}\n",
      "    49772    0.697    0.000    0.697    0.000 {built-in method _codecs.charmap_decode}\n",
      "   117407    0.057    0.000    0.057    0.000 {built-in method _collections._count_elements}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _heapq.heapify}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method _heapq.heapreplace}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _locale._getdefaultlocale}\n",
      "        1    0.000    0.000   36.425   36.425 {built-in method builtins.exec}\n",
      " 17258113    1.640    0.000    1.746    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "   234818    0.029    0.000    0.029    0.000 {built-in method builtins.len}\n",
      "        1    0.001    0.001    0.001    0.001 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      " 17023305    1.445    0.000    1.445    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   234814    0.035    0.000    0.035    0.000 {method 'end' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "   234814    0.138    0.000    0.138    0.000 {method 'match' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "   117407    0.040    0.000    0.040    0.000 {method 'startswith' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### TIEMPO DE EJECUCIÓN q2_memory ####\n",
    "cProfile.run(\"q2_memory(file_path)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memoria:\n",
    "\n",
    "    Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "    =============================================================\n",
    "        9   51.199 MiB   51.199 MiB           1   @profile\n",
    "        10                                         def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "        11   51.211 MiB    0.012 MiB           1       emoji_counts = Counter()\n",
    "        12\n",
    "        13   51.211 MiB    0.000 MiB           1       with open(file_path, 'r') as f:\n",
    "        14   53.863 MiB -3625.105 MiB      117408           for line in f:\n",
    "        15   53.863 MiB -3625.699 MiB      117407               tweet = json.loads(line)\n",
    "        16   53.863 MiB -3625.859 MiB      117407               content = tweet['content']\n",
    "        17\n",
    "        18                                                     # Se obtienen los emojis\n",
    "        19   53.863 MiB -12499.953 MiB      395143               emojis = [emoji['emoji'] for emoji in emoji_list(content)]\n",
    "        20\n",
    "        21                                                     # Se actualiza el contador con los emojis que se encontraron.\n",
    "        22   53.863 MiB -3625.887 MiB      117407               emoji_counts.update(emojis)\n",
    "        23\n",
    "        24   53.863 MiB    0.000 MiB           1       top_emojis = emoji_counts.most_common(10)\n",
    "        25\n",
    "        26   53.863 MiB    0.000 MiB           1       return top_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discusión de resultados**\n",
    "\n",
    "En términos de tiempo, q2_time es más rápido que q2_memory (24.301 segundos vs 36.425 segundos). Esto se debe a que q2_time lee todo el archivo JSON en memoria y lo convierte en un DataFrame de Pandas, y luego concatena todas las cadenas de tweets en una sola cadena. Esto es más rápido que leer el archivo línea por línea y procesar cada tweet individualmente, como lo hace q2_memory.\n",
    "\n",
    "Sin embargo, en términos de memoria, q2_memory es más eficiente que q2_time (53.863 MiB vs 1593.184 MiB). Esto se debe a que q2_memory solo necesita mantener una pequeña cantidad de datos en memoria a la vez, en lugar de crear una gran cadena que contenga todos los tweets. Además, q2_memory no crea una gran lista de emojis para cada tweet, sino que actualiza el contador en el lugar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos. Debe incluir las siguientes funciones:**\n",
    "\n",
    "**Optimización tiempo de ejecución**\n",
    "\n",
    "1. Importamos las librerías necesarias: typing para definir los tipos de las variables de entrada y salida, pandas para leer el archivo JSON y convertirlo en un DataFrame.\n",
    "2. Definimos la función q3_time que toma como entrada un archivo JSON y devuelve una lista de tuplas, donde cada tupla contiene un nombre de usuario y su frecuencia en el archivo JSON.\n",
    "3. Cargamos el archivo JSON en un DataFrame de Pandas.\n",
    "4. Extraemos las menciones de la columna mentionedUsers usando el método apply y una función lambda. La función lambda itera sobre cada elemento de la columna y extrae el valor de la clave username de cada diccionario en la lista, si la entrada es una lista. Si la entrada no es una lista, la función lambda devuelve una lista vacía. La función lambda se utiliza en lugar de una comprensión de lista para optimizar el tiempo de ejecución, ya que evita crear una gran lista de listas de menciones que contenga todas las menciones de todos los tweets.\n",
    "5. Aplanamos la lista de listas de menciones usando una comprensión de lista.\n",
    "6. Contamos las menciones por usuario usando el método value_counts de la columna mentions.\n",
    "7. Obtenemos los 10 usuarios con más menciones usando el método head de la Serie mention_counts.\n",
    "8. Renombramos las columnas de la DataFrame top_users para que la columna de nombres de usuario se llame username y la columna de frecuencias se llame count.\n",
    "9.Convertimos la DataFrame top_users en una lista de tuplas usando el método itertuples y devolvemos la lista.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Cargar el archivo JSON en un DataFrame de Pandas\n",
    "    #df = pd.read_json(file_path, lines=True)\n",
    "    \n",
    "    # Extraer las menciones de la columna 'mentionedUsers'\n",
    "    df['mentions'] = df['mentionedUsers'].apply(lambda x: [user['username'] for user in x] if isinstance(x, list) else [])\n",
    "    \n",
    "    # Aplanar la lista de listas de menciones\n",
    "    mentions = [mention for mentions in df['mentions'] for mention in mentions]\n",
    "    \n",
    "    # Contar las menciones por usuario\n",
    "    mention_counts = pd.Series(mentions).value_counts()\n",
    "    \n",
    "    # Obtener los 10 usuarios con más menciones\n",
    "    top_users = mention_counts.head(10).reset_index()\n",
    "    top_users.columns = ['username', 'count']\n",
    "    \n",
    "    return list(top_users.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "print(q3_time(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         275680 function calls (275631 primitive calls) in 0.418 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.029    0.029    0.029    0.029 3430477421.py:12(<listcomp>)\n",
      "        1    0.005    0.005    0.414    0.414 3430477421.py:4(q3_time)\n",
      "   117407    0.042    0.000    0.268    0.000 3430477421.py:9(<lambda>)\n",
      "    38034    0.218    0.000    0.218    0.000 3430477421.py:9(<listcomp>)\n",
      "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1033(_handle_fromlist)\n",
      "        1    0.004    0.004    0.418    0.418 <string>:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 _decorators.py:218(_format_argument_list)\n",
      "      3/2    0.000    0.000    0.004    0.002 _decorators.py:308(wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\n",
      "        1    0.000    0.000    0.000    0.000 _dtype.py:330(_name_includes_bit_suffix)\n",
      "        1    0.000    0.000    0.000    0.000 _dtype.py:346(_name_get)\n",
      "        1    0.000    0.000    0.000    0.000 _methods.py:61(_all)\n",
      "        2    0.000    0.000    0.000    0.000 _ufunc_config.py:132(geterr)\n",
      "        2    0.000    0.000    0.000    0.000 _ufunc_config.py:33(seterr)\n",
      "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:426(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:430(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 _ufunc_config.py:435(__exit__)\n",
      "        5    0.000    0.000    0.000    0.000 _validators.py:227(validate_bool_kwarg)\n",
      "        1    0.000    0.000    0.000    0.000 _validators.py:452(validate_ascending)\n",
      "        1    0.000    0.000    0.000    0.000 abc.py:100(__subclasscheck__)\n",
      "        3    0.000    0.000    0.000    0.000 abc.py:96(__instancecheck__)\n",
      "        1    0.031    0.031    0.031    0.031 algorithms.py:1003(value_counts_arraylike)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:115(_ensure_data)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:195(_reconstruct_data)\n",
      "        1    0.000    0.000    0.000    0.000 algorithms.py:233(_ensure_arraylike)\n",
      "        1    0.000    0.000    0.033    0.033 algorithms.py:913(value_counts)\n",
      "        2    0.000    0.000    0.000    0.000 api.py:381(default_index)\n",
      "        1    0.000    0.000    0.000    0.000 apply.py:1066(__init__)\n",
      "        1    0.002    0.002    0.304    0.304 apply.py:1085(apply)\n",
      "        1    0.000    0.000    0.000    0.000 apply.py:109(__init__)\n",
      "        1    0.000    0.000    0.302    0.302 apply.py:1136(apply_standard)\n",
      "        1    0.000    0.000    0.007    0.007 astype.py:192(astype_array)\n",
      "        1    0.000    0.000    0.007    0.007 astype.py:239(astype_array_safe)\n",
      "        1    0.000    0.000    0.000    0.000 astype.py:68(astype_nansafe)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:1025(view)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1056(astype)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:1736(name)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1787(_get_default_index_names)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:243(disallow_kwargs)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:2754(_is_all_dates)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:2785(_is_multi)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:286(is_dtype)\n",
      "        8    0.000    0.000    0.000    0.000 base.py:324(ndim)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:3756(get_loc)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:4203(_validate_positional_slice)\n",
      "      7/5    0.001    0.000    0.002    0.000 base.py:432(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:46(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:494(find)\n",
      "       14    0.000    0.000    0.000    0.000 base.py:5128(_values)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5154(_get_engine_target)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:5242(_validate_fill_value)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:5292(__contains__)\n",
      "       10    0.001    0.000    0.001    0.000 base.py:5342(__getitem__)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:54(shape)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:557(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:56(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:576(_ensure_array)\n",
      "        7    0.000    0.000    0.000    0.000 base.py:58(_validate_set_axis)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:590(_dtype_to_subclass)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:6289(_find_common_type_compat)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:6607(_maybe_cast_indexer)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:6620(_validate_indexer)\n",
      "      2/1    0.000    0.000    0.001    0.001 base.py:6882(insert)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:692(_simple_new)\n",
      "        3    0.000    0.000    0.001    0.000 base.py:710(_with_infer)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:730(_constructor)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:7315(ensure_index)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:7410(maybe_extract_name)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:742(__iter__)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:7434(_maybe_cast_data_without_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:823(_view)\n",
      "       11    0.000    0.000    0.000    0.000 base.py:872(_reset_identity)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:883(_engine)\n",
      "        1    0.000    0.000    0.034    0.034 base.py:894(value_counts)\n",
      "       25    0.000    0.000    0.000    0.000 base.py:927(__len__)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:988(dtype)\n",
      "        8    0.000    0.000    0.000    0.000 blocks.py:2088(maybe_coerce_values)\n",
      "        7    0.000    0.000    0.000    0.000 blocks.py:2117(get_block_type)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:2158(new_block_2d)\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:2169(new_block)\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:2183(check_ndim)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:222(make_block)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:2247(extend_blocks)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:2263(ensure_block_shape)\n",
      "        3    0.000    0.000    0.000    0.000 blocks.py:501(dtype)\n",
      "        1    0.000    0.000    0.007    0.007 blocks.py:505(astype)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:545(copy)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:822(shape)\n",
      "        4    0.000    0.000    0.000    0.000 blocks.py:826(iget)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:835(_slice)\n",
      "        3    0.000    0.000    0.000    0.000 cast.py:1179(maybe_infer_to_datetimelike)\n",
      "        1    0.000    0.000    0.017    0.017 cast.py:121(maybe_convert_platform)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:1423(sanitize_to_nanoseconds)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1537(common_dtype_categorical_compat)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1590(find_common_type)\n",
      "        3    0.000    0.000    0.000    0.000 cast.py:1620(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:1629(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:1631(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 cast.py:1636(<genexpr>)\n",
      "        3    0.016    0.005    0.016    0.005 cast.py:1764(construct_1d_object_array_from_listlike)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:1789(maybe_cast_to_integer_array)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:1932(np_can_hold_element)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:740(infer_dtype_from)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:757(infer_dtype_from_scalar)\n",
      "        1    0.000    0.000    0.000    0.000 cast.py:920(_maybe_infer_dtype_type)\n",
      "        5    0.000    0.000    0.000    0.000 common.py:1155(needs_i8_conversion)\n",
      "        9    0.000    0.000    0.000    0.000 common.py:1247(is_float_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:1279(is_bool_dtype)\n",
      "        9    0.000    0.000    0.000    0.000 common.py:1421(is_1d_only_ea_dtype)\n",
      "        5    0.000    0.000    0.000    0.000 common.py:1434(is_extension_array_dtype)\n",
      "       14    0.000    0.000    0.000    0.000 common.py:147(classes)\n",
      "       14    0.000    0.000    0.000    0.000 common.py:1488(is_ea_or_datetimelike_dtype)\n",
      "       14    0.000    0.000    0.000    0.000 common.py:149(<lambda>)\n",
      "        8    0.000    0.000    0.000    0.000 common.py:151(cast_scalar_indexer)\n",
      "       13    0.000    0.000    0.000    0.000 common.py:152(classes_and_not_datetimelike)\n",
      "        9    0.000    0.000    0.000    0.000 common.py:1557(get_dtype)\n",
      "       13    0.000    0.000    0.000    0.000 common.py:157(<lambda>)\n",
      "       27    0.000    0.000    0.000    0.000 common.py:1592(_is_dtype_type)\n",
      "        5    0.000    0.000    0.000    0.000 common.py:163(is_object_dtype)\n",
      "       11    0.000    0.000    0.000    0.000 common.py:1726(validate_all_hashable)\n",
      "       22    0.000    0.000    0.000    0.000 common.py:1745(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:1752(pandas_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:235(asarray_tuplesafe)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:293(maybe_iterable_to_list)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:303(is_null_slice)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:320(is_datetime64_dtype)\n",
      "        8    0.000    0.000    0.000    0.000 common.py:352(apply_if_callable)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:353(is_datetime64tz_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:394(is_timedelta64_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:538(is_string_or_object_np_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:556(require_length_match)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:586(is_dtype_equal)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:685(is_integer_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:737(is_signed_integer_dtype)\n",
      "        5    0.000    0.000    0.000    0.000 common.py:791(is_unsigned_integer_dtype)\n",
      "        7    0.000    0.000    0.000    0.000 common.py:96(is_bool_indexer)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:117(_get_single_key)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:135(_get_option)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:263(__call__)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:580(_select_options)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:598(_get_root)\n",
      "       12    0.000    0.000    0.000    0.000 config.py:612(_get_deprecated_option)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:639(_translate_key)\n",
      "        6    0.000    0.000    0.000    0.000 config.py:651(_warn_if_deprecated)\n",
      "       10    0.000    0.000    0.000    0.000 construction.py:400(extract_array)\n",
      "       13    0.000    0.000    0.000    0.000 construction.py:462(ensure_wrapped_if_datetimelike)\n",
      "        8    0.004    0.000    0.021    0.003 construction.py:494(sanitize_array)\n",
      "        8    0.000    0.000    0.000    0.000 construction.py:677(_sanitize_ndim)\n",
      "        8    0.000    0.000    0.000    0.000 construction.py:714(_sanitize_str_dtypes)\n",
      "        8    0.000    0.000    0.000    0.000 construction.py:734(_maybe_repeat)\n",
      "        7    0.000    0.000    0.000    0.000 construction.py:745(_try_cast)\n",
      "        5    0.000    0.000    0.000    0.000 construction.py:862(is_empty_data)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:357(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:360(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:363(__exit__)\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:763(value)\n",
      "       13    0.000    0.000    0.000    0.000 flags.py:49(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 flags.py:53(allows_duplicate_labels)\n",
      "       10    0.000    0.000    0.000    0.000 flags.py:85(allows_duplicate_labels)\n",
      "        1    0.000    0.000    0.002    0.002 frame.py:12034(_reindex_for_setitem)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:1413(itertuples)\n",
      "        3    0.000    0.000    0.000    0.000 frame.py:1484(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 frame.py:1497(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 frame.py:3701(_ixs)\n",
      "        2    0.000    0.000    0.000    0.000 frame.py:3756(__getitem__)\n",
      "        1    0.000    0.000    0.013    0.013 frame.py:3953(__setitem__)\n",
      "        1    0.000    0.000    0.011    0.011 frame.py:4130(_iset_item_mgr)\n",
      "        1    0.000    0.000    0.011    0.011 frame.py:4137(_set_item_mgr)\n",
      "        1    0.000    0.000    0.013    0.013 frame.py:4162(_set_item)\n",
      "        2    0.000    0.000    0.000    0.000 frame.py:4224(_ensure_valid_index)\n",
      "        4    0.000    0.000    0.000    0.000 frame.py:4247(_box_col_values)\n",
      "        4    0.000    0.000    0.011    0.003 frame.py:4261(_clear_item_cache)\n",
      "        2    0.000    0.000    0.000    0.000 frame.py:4264(_get_item_cache)\n",
      "        1    0.000    0.000    0.001    0.001 frame.py:4746(insert)\n",
      "        2    0.000    0.000    0.002    0.001 frame.py:4882(_sanitize_column)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:599(_constructor)\n",
      "        2    0.000    0.000    0.000    0.000 frame.py:608(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 frame.py:6120(reset_index)\n",
      "        2    0.000    0.000    0.000    0.000 frame.py:856(axes)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:1764(_ravel_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:1768(ravel)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:1877(_nonzero_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:1881(nonzero)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "        1    0.000    0.000    0.000    0.000 function_base.py:5364(_insert_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 function_base.py:5368(insert)\n",
      "        2    0.000    0.000    0.000    0.000 function_base.py:5558(_append_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 function_base.py:5562(append)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1996(__contains__)\n",
      "       13    0.000    0.000    0.000    0.000 generic.py:260(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 generic.py:333(attrs)\n",
      "       20    0.000    0.000    0.000    0.000 generic.py:354(flags)\n",
      "       88    0.000    0.000    0.000    0.000 generic.py:40(_check)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:4138(_check_setitem_copy)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:4260(_check_inplace_and_allows_duplicate_labels)\n",
      "       88    0.000    0.000    0.000    0.000 generic.py:45(_instancecheck)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:5479(head)\n",
      "        8    0.000    0.000    0.000    0.000 generic.py:551(_get_axis_number)\n",
      "        7    0.000    0.000    0.000    0.000 generic.py:565(_get_axis)\n",
      "       10    0.000    0.000    0.000    0.000 generic.py:5849(__finalize__)\n",
      "        7    0.000    0.000    0.000    0.000 generic.py:5893(__getattr__)\n",
      "       15    0.000    0.000    0.000    0.000 generic.py:5909(__setattr__)\n",
      "        1    0.000    0.000    0.008    0.008 generic.py:6081(astype)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:6263(copy)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:641(_info_axis)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:665(ndim)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:820(_set_axis)\n",
      "        3    0.000    0.000    0.000    0.000 indexing.py:1060(__getitem__)\n",
      "        6    0.000    0.000    0.000    0.000 indexing.py:1064(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 indexing.py:1065(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 indexing.py:140(iloc)\n",
      "        4    0.000    0.000    0.000    0.000 indexing.py:1449(_validate_key)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:1525(_is_scalar_access)\n",
      "        4    0.000    0.000    0.000    0.000 indexing.py:1538(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 indexing.py:1540(_validate_integer)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:1562(_getitem_tuple)\n",
      "        3    0.000    0.000    0.000    0.000 indexing.py:1593(_getitem_axis)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:1630(_get_slice_axis)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:2484(convert_to_index_sliceable)\n",
      "        4    0.000    0.000    0.000    0.000 indexing.py:2625(is_label_like)\n",
      "        1    0.000    0.000    0.000    0.000 indexing.py:2639(need_slice)\n",
      "        5    0.000    0.000    0.000    0.000 indexing.py:2652(check_deprecated_indexers)\n",
      "        6    0.000    0.000    0.000    0.000 indexing.py:2657(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 indexing.py:2668(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:843(_expand_ellipsis)\n",
      "        6    0.000    0.000    0.000    0.000 indexing.py:849(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:865(_validate_tuple_indexer)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:882(_is_nested_tuple_indexer)\n",
      "        6    0.000    0.000    0.000    0.000 indexing.py:889(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 indexing.py:900(_validate_key_length)\n",
      "        2    0.000    0.000    0.000    0.000 indexing.py:932(_getitem_lowerdim)\n",
      "        7    0.000    0.000    0.000    0.000 inference.py:189(is_array_like)\n",
      "        4    0.000    0.000    0.000    0.000 inference.py:267(is_dict_like)\n",
      "       12    0.000    0.000    0.000    0.000 inference.py:293(<genexpr>)\n",
      "       26    0.000    0.000    0.000    0.000 inference.py:326(is_hashable)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:73(isclass)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1051(from_blocks)\n",
      "        4    0.000    0.000    0.000    0.000 managers.py:1117(iget)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1169(iset)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1325(_iset_single)\n",
      "        1    0.000    0.000    0.001    0.001 managers.py:1373(insert)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1414(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1424(_insert_update_mgr_locs)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1434(_insert_update_blklocs_and_blknos)\n",
      "        6    0.000    0.000    0.000    0.000 managers.py:170(blknos)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1823(is_consolidated)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1831(_consolidate_check)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1841(_consolidate_inplace)\n",
      "        5    0.000    0.000    0.000    0.000 managers.py:186(blklocs)\n",
      "       10    0.000    0.000    0.000    0.000 managers.py:1868(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1892(from_blocks)\n",
      "        4    0.000    0.000    0.000    0.000 managers.py:1908(from_array)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1916(to_2d_mgr)\n",
      "        9    0.000    0.000    0.000    0.000 managers.py:1980(_block)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1994(getitem_mgr)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:2023(index)\n",
      "        6    0.000    0.000    0.000    0.000 managers.py:2027(dtype)\n",
      "       14    0.000    0.000    0.000    0.000 managers.py:2038(internal_values)\n",
      "        7    0.000    0.000    0.000    0.000 managers.py:226(set_axis)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:236(items)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:2365(_fast_count_smallints)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:2397(_using_copy_on_write)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:260(_clear_reference_block)\n",
      "        2    0.000    0.000    0.008    0.004 managers.py:297(apply)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:326(<dictcomp>)\n",
      "        1    0.000    0.000    0.008    0.008 managers.py:445(astype)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:612(copy)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:638(copy_func)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:641(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:988(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 missing.py:108(isna)\n",
      "        4    0.000    0.000    0.000    0.000 missing.py:191(_isna)\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:268(_isna_array)\n",
      "        3    0.000    0.000    0.000    0.000 missing.py:695(is_valid_na_for_dtype)\n",
      "       10    0.000    0.000    0.000    0.000 multiarray.py:1080(copyto)\n",
      "        3    0.000    0.000    0.000    0.000 multiarray.py:153(concatenate)\n",
      "        1    0.000    0.000    0.000    0.000 multiarray.py:892(bincount)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:133(_ensure_array)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:1330(normalize_axis_tuple)\n",
      "        2    0.000    0.000    0.000    0.000 numeric.py:1380(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:1389(_moveaxis_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:1393(moveaxis)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:1455(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:182(_validate_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:193(_ensure_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:2374(_array_equal_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:2378(array_equal)\n",
      "       10    0.000    0.000    0.000    0.000 numeric.py:274(full)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:382(_engine_type)\n",
      "        2    0.000    0.000    0.000    0.000 numerictypes.py:283(issubclass_)\n",
      "        1    0.000    0.000    0.000    0.000 numerictypes.py:357(issubdtype)\n",
      "        2    0.000    0.000    0.000    0.000 numerictypes.py:574(_can_coerce_all)\n",
      "       19    0.000    0.000    0.000    0.000 numerictypes.py:583(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 numerictypes.py:598(find_common_type)\n",
      "        1    0.000    0.000    0.000    0.000 numerictypes.py:668(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 numerictypes.py:669(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 range.py:174(_simple_new)\n",
      "        2    0.000    0.000    0.000    0.000 range.py:354(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:542(equals)\n",
      "       14    0.000    0.000    0.000    0.000 range.py:947(__len__)\n",
      "        3    0.000    0.000    0.000    0.000 re.py:250(compile)\n",
      "        3    0.000    0.000    0.000    0.000 re.py:289(_compile)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:1071(_get_values)\n",
      "        4    0.000    0.000    0.000    0.000 series.py:1270(_set_as_cached)\n",
      "        1    0.000    0.000    0.002    0.002 series.py:1431(reset_index)\n",
      "        1    0.000    0.000    0.001    0.001 series.py:1900(to_frame)\n",
      "       11    0.004    0.000    0.025    0.002 series.py:343(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 series.py:3576(sort_values)\n",
      "        1    0.000    0.000    0.305    0.305 series.py:4664(apply)\n",
      "        4    0.000    0.000    0.000    0.000 series.py:547(_constructor)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:551(_constructor_expanddim)\n",
      "        5    0.000    0.000    0.000    0.000 series.py:566(_set_axis)\n",
      "        6    0.000    0.000    0.000    0.000 series.py:597(dtype)\n",
      "       14    0.000    0.000    0.000    0.000 series.py:612(name)\n",
      "       11    0.000    0.000    0.000    0.000 series.py:662(name)\n",
      "       14    0.000    0.000    0.000    0.000 series.py:709(_values)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:765(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:962(_slice)\n",
      "        1    0.000    0.000    0.000    0.000 shape_base.py:19(_atleast_1d_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 shape_base.py:23(atleast_1d)\n",
      "        1    0.000    0.000    0.000    0.000 sorting.py:376(nargsort)\n",
      "        3    0.000    0.000    0.000    0.000 types.py:171(__get__)\n",
      "       21    0.000    0.000    0.000    0.000 typing.py:1333(cast)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:702(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:831(__subclasscheck__)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:67(is_list_like_indexer)\n",
      "        3    0.000    0.000    0.000    0.000 warnings.py:130(filterwarnings)\n",
      "        3    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\n",
      "        3    0.000    0.000    0.000    0.000 warnings.py:437(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 warnings.py:458(__enter__)\n",
      "        3    0.000    0.000    0.000    0.000 warnings.py:477(__exit__)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x00007FFBC63D5C60}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _warnings.warn}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000    0.418    0.418 {built-in method builtins.exec}\n",
      "      120    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "       31    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "       32    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "117998/117994    0.008    0.000    0.008    0.000 {built-in method builtins.isinstance}\n",
      "       67    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "  177/136    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "       21    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method numpy.geterrobj}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.seterrobj}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_datetime_array}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method pandas._libs.missing.checknull}\n",
      "        1    0.000    0.000    0.000    0.000 {method '_rebuild_blknos_and_blklocs' of 'pandas._libs.internals.BlockManager' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        4    0.011    0.003    0.011    0.003 {method 'clear' of 'dict' objects}\n",
      "        4    0.009    0.002    0.009    0.002 {method 'copy' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'increment_above' of 'pandas._libs.internals.BlockPlacement' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'item' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.dtypes_all_equal}\n",
      "        3    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_all_arraylike}\n",
      "        5    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool}\n",
      "       11    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\n",
      "       19    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
      "       10    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
      "       36    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
      "        9    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
      "        6    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "        1    0.026    0.026    0.294    0.294 {pandas._libs.lib.map_infer}\n",
      "        9    0.001    0.000    0.001    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### TIEMPO DE EJECUCIÓN q3_time ####\n",
    "cProfile.run(\"q3_time(file_path)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memoria:\n",
    "\n",
    "    Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "    =============================================================\n",
    "        6   75.102 MiB   75.102 MiB           1   @profile  #se puede descomentar para correr la función en la terminal con python -m memory_profiler q1_time.py y ver el uso de memoria.\n",
    "        7                                         def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "        8                                             # Cargar el archivo JSON en un DataFrame de Pandas\n",
    "        9 1504.672 MiB 1429.570 MiB           1       df = pd.read_json(file_path, lines=True)\n",
    "        10\n",
    "        11                                             # Extraer las menciones de la columna 'mentionedUsers'\n",
    "        12 1508.375 MiB    3.703 MiB      414286       df['mentions'] = df['mentionedUsers'].apply(lambda x: [user['username'] for user in x] if isinstance(x, list) else [])\n",
    "        13\n",
    "        14                                             # Aplanar la lista de listas de menciones\n",
    "        15 1510.125 MiB    1.750 MiB      220813       mentions = [mention for mentions in df['mentions'] for mention in mentions]\n",
    "        16\n",
    "        17                                             # Contar las menciones por usuario\n",
    "        18 1511.961 MiB    1.836 MiB           1       mention_counts = pd.Series(mentions).value_counts()\n",
    "        19\n",
    "        20                                             # Obtener los 10 usuarios con más menciones\n",
    "        21 1512.098 MiB    0.137 MiB           1       top_users = mention_counts.head(10).reset_index()\n",
    "        22 1512.098 MiB    0.000 MiB           1       top_users.columns = ['username', 'count']\n",
    "        23\n",
    "        24 1512.109 MiB    0.012 MiB           1       return list(top_users.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización de memoria en uso**\n",
    "\n",
    "1. Se crea un objeto Counter llamado mention_counts para contar las menciones.\n",
    "2. Se abre el archivo JSON farmers-protest-tweets-2021-2-4.json y se procesa cada línea.\n",
    "3. Para cada línea, se evalúa como un diccionario de Python y se extraen los usuarios mencionados de la columna 'mentionedUsers'.\n",
    "4. Se actualiza el contador mention_counts con las menciones de cada línea.\n",
    "5. Se obtienen los 10 usuarios con más menciones utilizando el método most_common del objeto Counter.\n",
    "6. Se devuelve una lista de tuplas con los 10 usuarios con más menciones.\n",
    "\n",
    "En este código, no es necesario aplanar explícitamente una lista, ya que el objeto Counter se encarga de contar automáticamente las menciones de cada usuario, incluso si se encuentran en listas anidadas. El método most_common devuelve una lista de tuplas con los 10 usuarios con más menciones y su respectivo recuento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "from q3_memory import q3_memory\n",
    "result = q3_memory(file_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1898723 function calls in 4.797 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.001    0.001    4.797    4.797 <string>:1(<module>)\n",
      "   117407    0.106    0.000    2.772    0.000 __init__.py:299(loads)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:581(__init__)\n",
      "        1    0.000    0.000    0.003    0.003 __init__.py:600(most_common)\n",
      "   117408    0.051    0.000    0.202    0.000 __init__.py:649(update)\n",
      "        1    0.000    0.000    0.000    0.000 _bootlocale.py:11(getpreferredencoding)\n",
      "   117407    0.025    0.000    0.057    0.000 abc.py:96(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 codecs.py:260(__init__)\n",
      "    49772    0.021    0.000    0.584    0.000 cp1252.py:22(decode)\n",
      "   117407    0.140    0.000    2.635    0.000 decoder.py:332(decode)\n",
      "   117407    2.381    0.000    2.381    0.000 decoder.py:343(raw_decode)\n",
      "        1    0.003    0.003    0.003    0.003 heapq.py:521(nlargest)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:563(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 heapq.py:577(<listcomp>)\n",
      "    38034    0.011    0.000    0.011    0.000 q3_memory.py:18(<listcomp>)\n",
      "        1    1.225    1.225    4.796    4.796 q3_memory.py:7(q3_memory)\n",
      "   117407    0.032    0.000    0.032    0.000 {built-in method _abc._abc_instancecheck}\n",
      "    49772    0.562    0.000    0.562    0.000 {built-in method _codecs.charmap_decode}\n",
      "   117407    0.056    0.000    0.056    0.000 {built-in method _collections._count_elements}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _heapq.heapify}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method _heapq.heapreplace}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _locale._getdefaultlocale}\n",
      "        1    0.000    0.000    4.797    4.797 {built-in method builtins.exec}\n",
      "   234814    0.047    0.000    0.104    0.000 {built-in method builtins.isinstance}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "   117408    0.011    0.000    0.011    0.000 {built-in method builtins.len}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   234814    0.019    0.000    0.019    0.000 {method 'end' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "   234814    0.084    0.000    0.084    0.000 {method 'match' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "   117407    0.021    0.000    0.021    0.000 {method 'startswith' of 'str' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### TIEMPO DE EJECUCIÓN q3_memory ####\n",
    "cProfile.run(\"q3_memory(file_path)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memoria:\n",
    "\n",
    "    Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "    =============================================================\n",
    "        6   41.258 MiB   41.258 MiB           1   @profile  #se puede descomentar para correr la función en la terminal con python -m memory_profiler q1_time.py y ver el uso de memoria.\n",
    "        7                                         def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "        8                                             # Crear un objeto Counter para contar las menciones\n",
    "        9   41.270 MiB    0.012 MiB           1       mention_counts = Counter()\n",
    "        10\n",
    "        11                                             # Abrir el archivo y procesar cada línea\n",
    "        12   41.270 MiB    0.000 MiB           1       with open(file_path, 'r') as f:\n",
    "        13   44.461 MiB -13878.895 MiB      117408           for line in f:\n",
    "        14                                                     # Evaluar la línea como un diccionario de Python\n",
    "        15   44.461 MiB -13878.473 MiB      117407               tweet = json.loads(line)\n",
    "        16\n",
    "        17                                                     # Extraer los usuarios mencionados de la columna 'mentionedUsers'\n",
    "        18   44.461 MiB -34503.359 MiB      296878               mentions = [user['username'] for user in tweet['mentionedUsers']] if tweet['mentionedUsers'] else []\n",
    "        19\n",
    "        20                                                     # Actualizar el contador con las menciones de esta línea\n",
    "        21   44.461 MiB -13878.625 MiB      117407               mention_counts.update(mentions)\n",
    "        22\n",
    "        23                                             # Obtener los 10 usuarios con más menciones utilizando el método most_common\n",
    "        24   43.988 MiB   -0.473 MiB           1       top_users = mention_counts.most_common(10)\n",
    "        25\n",
    "        26   43.988 MiB    0.000 MiB           1       return top_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discusión de Resultados**\n",
    "\n",
    "En términos de tiempo de ejecución, q3_time es más rápido que q3_memory, ya que q3_time tarda 0.418 segundos en completarse, mientras que q3_memory tarda 4.797 segundos. q3_time es más rápido que q3_memory porque q3_time utiliza operaciones vectorizadas de Pandas para procesar las menciones en lugar de iterar sobre cada elemento de la lista de menciones.\n",
    "\n",
    "En cuanto al uso de memoria, q3_memory utiliza significativamente menos memoria que q3_time. q3_memory utiliza una media de 43.988 MiB de memoria, mientras que q3_time utiliza una media de 1512.109 MiB de memoria. Esto se debe a que q3_memory no crea una columna adicional en el DataFrame de Pandas para almacenar las menciones, y tampoco aplana explícitamente la lista de menciones. Además, q3_memory utiliza un objeto Counter en lugar de una Serie de Pandas para contar las menciones, lo que reduce aún más el uso de memoria."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
